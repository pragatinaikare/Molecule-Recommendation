​The molecules recommended by the classical recommendation methods in Stage I are limited to the molecules which appear in the MolRec data. Therefore, in Stage II, we use a Variational Autoencoder to generate novel molecules which do not appear in the MolRec data. To align the generated molecules with researcher interests, we input the molecules recommended in Stage I to the VAE.

​

The VAE architecture we used is JTVAE, a GNN VAE which takes a 2-stage approach to molecule generation. In the first stage, a coarse view of the molecule is generated by assembling a tree representation of the molecule, where each node in the tree is a chemical substructure, and an edge indicates that at least one of the atoms in each substructure share a bond. These structures are selected from a vocabulary of valid chemical structures, which ensures that the overall generated molecule is chemically valid. In the second stage, the finer details of the molecule are resolved by generating the bonds between atoms in neighboring substructures. The figure below taken from the JTVAE paper illustrates this framework.

​Since there are 2 stages, there are two latent vectors per molecule, one for the tree structure and one for the bonds. Given these two vectors for each of the reference molecules, we get each of the latent vectors for the new molecule by averaging over the latent vectors for the reference molecules. We then generate the recommended molecule by passing the averaged latent vectors to the decoder of the VAE. 


We trained JTVAE for 20 epochs on the ZINC250K dataset of 250k molecules. Below, various training metrics are visualized on the y-axis, with epoch on the x-axis. beta indicates the weight of the KL regularizer which drives latent vectors to be approximately normally distributed, KL is the Kullback-Leibler divergence, and assm/topo/word are reconstruction accuracies. The black curve shows a model trained with the KL regularization weight kept at 0, making it a regular autoencoder, while the green curve anneals the weight up to 0.01. As can be seen, increasing the strength of the regularizer decreases the divergence as the latents tend to Gaussianity, but it reduces reconstruction accuracy. We employ the model shown in green for recommendation. 

We next show several recontructions from the test set. Further reconstructions are available on GitHub.

We finally show recommendations conditioned on 2 reference molecules. To obtain the recommendation, we sample latent vectors for each of the reference molecules from the encoder. We then set the latents for the recommended molecule as the average of these latent vectors. The recommended molecule is then generated by passing the averaged latents through the decoder. Further recommendations are available on GitHub.

We open source the weights for our trained JTVAEs on GitHub. Please see mol_rec.ipynb for a demonstration of how to load and use the trained models. 


Exploring the vast and growing landscape of chemical compounds is a significant challenge for researchers, therefore making the development of an effective chemical recommender system not just interesting but crucial. Building such a system has the potential to revolutionize how scientists discover and interact with chemical data, enhancing their research productivity and sparking innovation across chemistry and allied sciences. Previous works on recommendation of chemical compounds has been limited and not widely explored, indicating a significant opportunity for developing systems that can effectively navigate, predict and recommend novel and existing chemical compounds. The gap in the literature underscores the necessity for methods that integrate diverse algorithmic approaches, aiming to improve the discovery and identification process within extensive chemical datasets. 

​

Towards this goal, we introduce a hybrid chemical recommender system which leverages a combination of algorithms, including collaborative filtering, content-based approaches, and Graph Neural Network variational autoencoders to effectively identify and recommend compounds of interest. It focuses on introducing scientific researchers to potentially unknown chemical compounds within large-scale chemical datasets, enhancing discovery and research efficiency in chemistry and related fields.  

​

Our end-to-end recommendation model is outlined in the figure above. In the first stage, we use classical IR methods such as collaborative filtering and content-based approaches to recommend multiple reference molecules to each researcher based on their previous research interests. This is done using a dataset of our own construction which lists molecules researchers have interacted with in their previous papers, described in greater detail at MolRec Data. The approaches in the first stage are described in greater detail at Stage I: Classical Recommendation. In the second stage, we use these reference molecules and a variational autoencoder GNN to recommend novel molecules to the researcher beyond the molecules in the dataset, described in greater detail at Stage II: Deep Generative Model.

​

We next show several end-to-end recommendations for selected researchers. Please visit the end-to-end recommendation visualization section of our GitHub for more. In these visualizations, the top row shows reference molecules that the researcher has previously interacted with in their work. The Stage I Classical Recommendation methods use these reference molecules to recommend several molecules from the MolRec data, shown in the middle row. Finally, given the Stage I recommendations, the Stage II VAE generates a novel molecule, which is shown in the third and final row.



​

​



​
